{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Übung10_Regularisierung.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VggRNKxkc2VC"
      },
      "source": [
        "## Grundlagen Maschineller Lernverfahren | ML_INF19A | 2021\n",
        "**Datum: 11.11.2021**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2TDBo53c4ty"
      },
      "source": [
        "# Regularisierung\n",
        "Ressourcen: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDUFvin585wC"
      },
      "source": [
        "# Lade notwendigen Bibliotheken\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vltfaXzsdBmK"
      },
      "source": [
        "## Erzeuge Daten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewjVeZHG8_oI"
      },
      "source": [
        "#Setup Pseudo Zufallszahlen\n",
        "np.random.seed(2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld2jdKhO9BZw"
      },
      "source": [
        "# Daten erstellen\n",
        "n_samples = 75\n",
        "x_lim = 2\n",
        "\n",
        "X = -x_lim * np.random.rand(n_samples, 1) + x_lim * np.random.rand(n_samples, 1)# Zufallswerte für die X-Achse\n",
        "y = 0.25 + 0.75 * X**2 + 0.75 * np.random.rand(n_samples, 1) # Zufallswerte für die Y-Achse\n",
        "\n",
        "# \"Format\" der erzeugten Daten anzeigen\n",
        "print(\"Datensatz X:\", X.shape)\n",
        "\n",
        "# Daten anzeigen\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gpgqs8ndsJ6"
      },
      "source": [
        "## Trenne in Daten für Training und Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C4DNRgnCD75"
      },
      "source": [
        "# Lade Bibliothek\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uosDmDLjCM2o"
      },
      "source": [
        "# Führe Trennung durch\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aslGCdECVMI"
      },
      "source": [
        "# Prüfe Dimensionen\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9_qSVhuaISD"
      },
      "source": [
        "## Anwendung\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH_5oFLKGqQ0"
      },
      "source": [
        "### Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlPZOABQHcJk"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.linear_model import Ridge # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ufD52eMjoLl"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "pf = PolynomialFeatures(degree = 13)\n",
        "\n",
        "# Erweitere Datensätze\n",
        "X_train_poly = pf.fit_transform(X_train)\n",
        "X_test_poly = pf.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBcV7ZchH6ZL"
      },
      "source": [
        "reg_ridge_1 = Ridge(alpha = 0) # Ohne Regularisierung\n",
        "reg_ridge_2 = Ridge(alpha = 8) # Ein wenig Regularisierung\n",
        "reg_ridge_3 = Ridge(alpha = 1000) # Sehr starke Regularisierung"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S5QIAqjAP3x"
      },
      "source": [
        "reg_ridge_1.fit(X_train_poly, y_train)\n",
        "y_pred_train1 = reg_ridge_1.predict(X_train_poly)\n",
        "y_pred_test1 = reg_ridge_1.predict(X_test_poly)\n",
        "\n",
        "reg_ridge_2.fit(X_train_poly, y_train)\n",
        "y_pred_train2 = reg_ridge_2.predict(X_train_poly)\n",
        "y_pred_test2 = reg_ridge_2.predict(X_test_poly)\n",
        "\n",
        "reg_ridge_3.fit(X_train_poly, y_train)\n",
        "y_pred_train3 = reg_ridge_3.predict(X_train_poly)\n",
        "y_pred_test3 = reg_ridge_3.predict(X_test_poly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaHmJM9_A7W4"
      },
      "source": [
        "# Erstelle X Werte für das Zeichnen einer Geraden\n",
        "Xline = np.linspace(np.min(X), np.max(X), 100)\n",
        "Xline_poly = pf.transform(Xline.reshape(100, 1))\n",
        "\n",
        "# Plot der Datenmenge, der Geraden und der beiden neuen X_unknown Werte\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(X,y,'b.')\n",
        "plt.plot(X_train, y_train,'r^')\n",
        "plt.plot(X_test, y_test,'m+')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.plot(Xline, reg_ridge_1.predict(Xline_poly).reshape(-1,1), 'g', label=\"alpha = 0\")\n",
        "plt.plot(Xline, reg_ridge_2.predict(Xline_poly).reshape(-1,1), 'b', label=\"alpha = 8\")\n",
        "plt.plot(Xline, reg_ridge_3.predict(Xline_poly).reshape(-1,1), 'y', label=\"alpha = 1000\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0NrF17BJT0l"
      },
      "source": [
        "### Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz5P0PCTJXgE"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.linear_model import Lasso # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd0SnpuPJU5b"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "pf = PolynomialFeatures(degree = 13)\n",
        "\n",
        "# Erweitere Datensätze\n",
        "X_train_poly = pf.fit_transform(X_train)\n",
        "X_test_poly = pf.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v9qxso4JcjT"
      },
      "source": [
        "reg_lasso_1 = Lasso(alpha = 0) # Ohne Regularisierung\n",
        "reg_lasso_2 = Lasso(alpha = 0.3) # Ein wenig Regularisierung\n",
        "reg_lasso_3 = Lasso(alpha = 2) # Sehr starke Regularisierung"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JaZuYJ0Josp"
      },
      "source": [
        "reg_lasso_1.fit(X_train_poly, y_train)\n",
        "y_pred_train1 = reg_lasso_1.predict(X_train_poly)\n",
        "y_pred_test1 = reg_lasso_1.predict(X_test_poly)\n",
        "\n",
        "reg_lasso_2.fit(X_train_poly, y_train)\n",
        "y_pred_train2 = reg_lasso_2.predict(X_train_poly)\n",
        "y_pred_test2 = reg_lasso_2.predict(X_test_poly)\n",
        "\n",
        "reg_lasso_3.fit(X_train_poly, y_train)\n",
        "y_pred_train3 = reg_lasso_3.predict(X_train_poly)\n",
        "y_pred_test3 = reg_lasso_3.predict(X_test_poly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuP_IOwXJ72a"
      },
      "source": [
        "# Erstelle X Werte für das Zeichnen einer Geraden\n",
        "Xline = np.linspace(np.min(X), np.max(X), 100)\n",
        "Xline_poly = pf.transform(Xline.reshape(100, 1))\n",
        "\n",
        "# Plot der Datenmenge, der Geraden und der beiden neuen X_unknown Werte\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(X,y,'b.')\n",
        "plt.plot(X_train, y_train,'r^')\n",
        "plt.plot(X_test, y_test,'m+')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.plot(Xline, reg_lasso_1.predict(Xline_poly).reshape(-1,1), 'g', label=\"alpha = 0\")\n",
        "plt.plot(Xline, reg_lasso_2.predict(Xline_poly).reshape(-1,1), 'b', label=\"alpha = 0.3\")\n",
        "plt.plot(Xline, reg_lasso_3.predict(Xline_poly).reshape(-1,1), 'y', label=\"alpha = 2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuozUNKFNKNq"
      },
      "source": [
        "### ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d-aW5eMNLUJ"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.linear_model import ElasticNet # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
        "\n",
        "# Lade Bibliotheken\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "pf = PolynomialFeatures(degree = 13)\n",
        "\n",
        "# Erweitere Datensätze\n",
        "X_train_poly = pf.fit_transform(X_train)\n",
        "X_test_poly = pf.fit_transform(X_test)\n",
        "\n",
        "reg_en_1 = ElasticNet(alpha = 0, l1_ratio = 0.6) # Ohne Regularisierung\n",
        "reg_en_2 = ElasticNet(alpha = 1, l1_ratio = 0.6) # Ein wenig Regularisierung\n",
        "reg_en_3 = ElasticNet(alpha = 100, l1_ratio = 0.6) # Sehr starke Regularisierung\n",
        "\n",
        "reg_en_1.fit(X_train_poly, y_train)\n",
        "y_pred_train1 = reg_en_1.predict(X_train_poly)\n",
        "y_pred_test1 = reg_en_1.predict(X_test_poly)\n",
        "\n",
        "reg_en_2.fit(X_train_poly, y_train)\n",
        "y_pred_train2 = reg_en_2.predict(X_train_poly)\n",
        "y_pred_test2 = reg_en_2.predict(X_test_poly)\n",
        "\n",
        "reg_en_3.fit(X_train_poly, y_train)\n",
        "y_pred_train3 = reg_en_3.predict(X_train_poly)\n",
        "y_pred_test3 = reg_en_3.predict(X_test_poly)\n",
        "\n",
        "# Erstelle X Werte für das Zeichnen einer Geraden\n",
        "Xline = np.linspace(np.min(X), np.max(X), 100)\n",
        "Xline_poly = pf.transform(Xline.reshape(100, 1))\n",
        "\n",
        "# Plot der Datenmenge, der Geraden und der beiden neuen X_unknown Werte\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(X,y,'b.')\n",
        "plt.plot(X_train, y_train,'r^')\n",
        "plt.plot(X_test, y_test,'m+')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.plot(Xline, reg_en_1.predict(Xline_poly).reshape(-1,1), 'g', label=\"alpha = 0\")\n",
        "plt.plot(Xline, reg_en_2.predict(Xline_poly).reshape(-1,1), 'b', label=\"alpha = 1\")\n",
        "plt.plot(Xline, reg_en_3.predict(Xline_poly).reshape(-1,1), 'y', label=\"alpha = 100\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFmlKwD4Orio"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJVDvPLRmJ-I"
      },
      "source": [
        "Die Architektur entspricht der aus der Übung zu Neuronalen Netzwerken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3wpyVjOsz6"
      },
      "source": [
        "# Lade Bibliothek\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Lade Datensatz\n",
        "data = load_iris()\n",
        "\n",
        "# Daten in Eingabe (X) und Labels (y) sortieren und \"lokal\" abspeichern\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Lade Bibliothek\n",
        "from sklearn.preprocessing import normalize # Normalisiere die Daten\n",
        "\n",
        "# Führe Vorverarbeitung durch\n",
        "X_norm = normalize(X) # NUR Eingabedaten, nicht die Label!\n",
        "\n",
        "# Lade Bibliothek\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Führe Trennung durch\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm,y,test_size=0.2)\n",
        "\n",
        "# Lade Bibliotheken\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential # Modelinstanz\n",
        "from tensorflow.keras.layers import Dense # Einzelne Layer\n",
        "from tensorflow.keras import Input # Spezieller Eingabelayer\n",
        "\n",
        "# NEU\n",
        "from tensorflow.keras.layers import Dropout # Dropout Layer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Prüfe wieviele Label/Klassen in der Aufgabe vorkommen \n",
        "num_classes = len(np.unique(y_train)) # -> bestimmt die Anzahl der Knoten im Ausgabelayer\n",
        "\n",
        "# Prüfe ob für Training und Test gleich viele Klassen vorhanden sind\n",
        "assert len(np.unique(y_train)) == len(np.unique(y_test))\n",
        "\n",
        "\n",
        "\n",
        "## Setup Hyperparameter des Neuronalen Netzwerkes\n",
        "\n",
        "# Anzahl der Knoten im Eingabelayer\n",
        "input_size = X_norm.shape[1:] # Nur Anzahl der Features relevant (150 stellt Batch-Dimension dar)\n",
        "\n",
        "# Anzahl der Knoten im Ausgabelayer\n",
        "output_size = num_classes # Speichere Anzahl der verschiedenen Klassen\n",
        "\n",
        "# Größe des Batches beim Training\n",
        "batch_size = 10\n",
        "\n",
        "# Anzahl der Epochen beim Training\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "# Lade Bibliothek\n",
        "from tensorflow.keras.utils import to_categorical # OneHot-Encoding (vgl. Doku: https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)\n",
        "\n",
        "# Umwandlung in One-Hot Vektor (vgl. Dokumentation \"to_categorical\")\n",
        "y_train_1hot = to_categorical(y_train, num_classes)\n",
        "y_test_1hot = to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCVXF56FmXsE"
      },
      "source": [
        "# Erstelle eine Instanz des Sequential Modells\n",
        "model = Sequential()\n",
        "\n",
        "# Definition des einfachen Modells (Struktur: Input -> Hidden -> Output)\n",
        "\n",
        "# Eingabe\n",
        "model.add(Input(shape=X_norm.shape[1:], name=\"Eingabe\")) # Ohne Batch Dimension, nur \"X-Achsen\" Dimension\n",
        "\n",
        "# Hidden Layer (3x)\n",
        "model.add(Dense(1000, activation=\"relu\", name=\"Hidden1\"))\n",
        "# NEU\n",
        "model.add(Dropout(rate = 0.2, name= \"Dropout1\")) # rate = 0.2 -> 0.9999\n",
        "model.add(Dense(500, activation=\"relu\", name=\"Hidden2\"))\n",
        "model.add(Dense(300, activation=\"relu\", name=\"Hidden3\"))\n",
        "\n",
        "# Ausgabe\n",
        "model.add(Dense(3, activation=\"softmax\", name=\"Ausgabe\")) # Hinweis: Bei mehreren Klassen nimmt man in der Regel die Softmax Aktivierungsfunktion (weitere Infos: vgl. Literatur)\n",
        "\n",
        "# \"Baue\" das Modell zusammen\n",
        "model.compile(loss='categorical_crossentropy', metrics='accuracy') # Angeben von diversen Hyperparametern (vgl. Doku für mehr Informationen)\n",
        "\n",
        "# Modell anzeigen\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZs_xgdhmgAO"
      },
      "source": [
        "# Training über die bekannte Funktion \"fit\" unter Angabe von Hyperparametern (vgl. Dokumentation: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit)\n",
        "model.fit(X_train, y_train_1hot, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "# Evaluiere das Modell auf Basis der Validierungsdatenmenge\n",
        "model.evaluate(X_test, y_test_1hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLTkuLawO_eZ"
      },
      "source": [
        "### Early Stopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT5g4AotpHqp"
      },
      "source": [
        "**Anwendung bei \"traditionellen\" ML Ansätze wie SGDClassifier**\n",
        "\n",
        "* Vgl. Doku und verwende den entsprechenden Parameter \"early_stopping = True\" wenn verfügbar (z.B. SGDClassifier) \n",
        "* Wenn kein Parameter vorhanden ist prüfe für jede Trainingsiteration die Performancewerte für die Validierungsdaten und entscheide anhand eines Kriteriums (z.B. ob der Wert wieder steigt) ob das Training abgebrochen werden soll.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPLAplMQqmg8"
      },
      "source": [
        "**Anwendung bei Neuronalen Netzwerken**\n",
        "\n",
        "- Verwende Callbacks (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxtLLa7OtfqS"
      },
      "source": [
        "# Lade Bibliothek\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Definiere Callback\n",
        "cb = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFOzVCAAoqP4"
      },
      "source": [
        "# Hinweis: Verwende das Modell \"model\" aus dem Abschnitt \"Dropout\"!\n",
        "\n",
        "# Training diesmal unter Verwendung des Callbacks\n",
        "model.fit(X_train, y_train_1hot, validation_data=(X_test, y_test_1hot), batch_size=batch_size, epochs=50, verbose=1, callbacks=[cb])\n",
        "\n",
        "# Evaluiere das Modell auf Basis der Validierungsdatenmenge\n",
        "model.evaluate(X_test, y_test_1hot)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}