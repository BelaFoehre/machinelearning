{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Übung9_Modellperformance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zokhIMJKCqwG"
      },
      "source": [
        "## Grundlagen Maschineller Lernverfahren | ML_INF19A | 2021\n",
        "**Datum: 09.11.2021**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIppqvlSCvKl"
      },
      "source": [
        "# Modellperformance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpKJ-WrFCC92"
      },
      "source": [
        "# Bibliotheken laden\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Zufall \"beeinflussen\"\n",
        "np.random.seed(2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxm8Ey2_C1SG"
      },
      "source": [
        "## Datensatz erstellen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSjZrwMeCznP"
      },
      "source": [
        "# Lade Bibliothek\n",
        "from sklearn.datasets import make_classification # https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfwX9c-NCzp2"
      },
      "source": [
        "# Erstelle Datensatz\n",
        "X,y  = make_classification(n_samples = 3000, n_features = 10, n_classes = 2, random_state = 4711)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNSli3BRCzsN"
      },
      "source": [
        "# Ein Blick in die Daten werfen\n",
        "print(X)\n",
        "print(y)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWE3hb_AC6hc"
      },
      "source": [
        "# Visualisiere die Daten (nur Features x1 und x6 <- Willkürlich gewählt)\n",
        "plt.plot(X[:, 0][y==0], X[:, 5][y==0], \"bv\")\n",
        "plt.plot(X[:, 0][y==1], X[:, 5][y==1], \"go\")\n",
        "\n",
        "# Erinnerung: Visualisierung in höher-dimensionalen Räumen sehr schelcht darstellbar!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwSFEDcgC6jo"
      },
      "source": [
        "# Erstelle Datenmengen für Training und Validierung\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4711)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5eTzHKTchSA"
      },
      "source": [
        "## Modell erstellen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8fhpFHTC6mB"
      },
      "source": [
        "# Lade Bibliothek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sys\n",
        "\n",
        "# Erstelle Instanz\n",
        "model = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l66K2lr2DHVs"
      },
      "source": [
        "## Lernkurve zeichnen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-nw-KXC6qn"
      },
      "source": [
        "# Zeige Verteilung der Instanzen für Training und Testing\n",
        "num_instances_train = len(X_train)\n",
        "num_instances_test = len(X_test)\n",
        "\n",
        "print(num_instances_train, num_instances_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvExaBOZC6oR"
      },
      "source": [
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "\n",
        "# Lege leere Liste an (darin werden später die Fehlerwerte gespeichert)\n",
        "list_errors_train_ll = []\n",
        "list_errors_test_ll = []\n",
        "list_errors_train_acc = []\n",
        "list_errors_test_acc = []\n",
        "\n",
        "# Durchlaufe alle Trainingsinstanzen\n",
        "for max_instances in range(1, num_instances_train):\n",
        "  \n",
        "  # Wähle iterativ immer mehr Trainingsinstanzen aus\n",
        "  current_X_train = X_train[:max_instances]\n",
        "  current_y_train = y_train[:max_instances]\n",
        "\n",
        "  # Zeige die Dimension des aktuellen Trainingsdatensatzes an\n",
        "  if max_instances % 100 == 0:\n",
        "    print(current_X_train.shape, \" / \" , current_y_train.shape)\n",
        "\n",
        "  try: # Vorkehrung um Fehler im Programmablauf abzufangen\n",
        "    \n",
        "    # Trainiere mit aktueller Trainingsdatenmenge\n",
        "    model.fit(current_X_train, current_y_train)\n",
        "\n",
        "    # ----------\n",
        "\n",
        "    # Vorhersagen\n",
        "    y_predict_train = model.predict(current_X_train) # nur die bisher im Training gesehenen\n",
        "    y_predict_test = model.predict(X_test) # Alle Validierungsinstanzen!\n",
        "  \n",
        "    # ----------\n",
        "\n",
        "    # Berechne LogLoss Fehlerwerte\n",
        "    error_train_logloss = log_loss(current_y_train, y_predict_train)\n",
        "    error_test_logloss = log_loss(y_test, y_predict_test)\n",
        "\n",
        "    # Speichere Fehlerwerte in Liste\n",
        "    list_errors_train_ll.append(error_train_logloss)\n",
        "    list_errors_test_ll.append(error_test_logloss)\n",
        "\n",
        "    # ----------\n",
        "    \n",
        "    # Berechne Accuracy Score (für alternative Darstellung des Performanceverlaufs)\n",
        "    error_train_accuracy = accuracy_score(current_y_train, y_predict_train)\n",
        "    error_test_accuracy = accuracy_score(y_test, y_predict_test)\n",
        "\n",
        "    # Speichere Accurancy Scores in Liste\n",
        "    list_errors_train_acc.append(error_train_accuracy)\n",
        "    list_errors_test_acc.append(error_test_accuracy)\n",
        "  \n",
        "  except ValueError: # Fange Fehler mit ValueError ab\n",
        "    print(\"Ignoriere -> \" ,sys.exc_info()) # Gebe Hinweis aus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-8Bk7wDKlGW"
      },
      "source": [
        "# Zeichne LogLoss-Fehler Verlauf\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(list_errors_train_ll, label=\"Training\")\n",
        "plt.plot(list_errors_test_ll, label=\"Validierung\")\n",
        "plt.xlabel(\"Trainingsdateninstanzen\")\n",
        "plt.ylabel(\"LogLoss Fehler\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Q8kRDdL4Af"
      },
      "source": [
        "# Zeichne Accuracy Verlauf\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(list_errors_train_acc, label=\"Training\")\n",
        "plt.plot(list_errors_test_acc, label=\"Validierung\")\n",
        "plt.xlabel(\"Trainingsdateninstanzen\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPkf6jBOM_Ov"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwlySCEoC6vQ"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj4afwhLOxVc"
      },
      "source": [
        "## Hinweis: Trainiere das Modell von oben nochmal neu\n",
        "\n",
        "# Erstelle Instanz\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Trainiere mit aktueller Trainingsdatenmenge\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersagen\n",
        "y_predict_train = model.predict(X_train) # nur die bisher im Training gesehenen\n",
        "y_predict_test = model.predict(X_test) # Alle Validierungsinstanzen!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R_HnUYbdohw"
      },
      "source": [
        "# Aufbau der Confusion Matrix\n",
        "# TN  FP\n",
        "# FN  TP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdOahyCeC6xk"
      },
      "source": [
        "# Berechne ConfusionMatrix für Trainingsdaten\n",
        "confusion_matrix(y_train, y_predict_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_K6BMDzOmVk"
      },
      "source": [
        "# Berechne ConfusionMatrix für Testdaten\n",
        "confusion_matrix(y_test, y_predict_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwY2ggXpPT-_"
      },
      "source": [
        "# Zeichne ConfusionMatrix für Training und Test (mit angepasster Formatierung der Zahlen)\n",
        "plot_confusion_matrix(model, X_train, y_train, values_format=\"4d\")\n",
        "plot_confusion_matrix(model, X_test, y_test, values_format=\"4d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNjOxrLQNA89"
      },
      "source": [
        "## Accuracy / Precision / Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9et-LSPsNEZE"
      },
      "source": [
        "# Lade Bibliotheken\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANWFqJdJQMYW"
      },
      "source": [
        "# Accuracy Werte\n",
        "print(\"[Accuracy] Trainingsdaten:\\t\", accuracy_score(y_train, y_predict_train))\n",
        "print(\"[Accuracy] Testdaten:\\t\\t\", accuracy_score(y_test, y_predict_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_ceeZMJQWME"
      },
      "source": [
        "# Precision Werte\n",
        "print(\"[Precision] Trainingsdaten:\\t\", precision_score(y_train, y_predict_train))\n",
        "print(\"[Precision] Testdaten:\\t\\t\", precision_score(y_test, y_predict_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPVYjcIXQp9U"
      },
      "source": [
        "# Recall Werte\n",
        "print(\"[Recall] Trainingsdaten:\\t\", recall_score(y_train, y_predict_train))\n",
        "print(\"[Recall] Testdaten:\\t\\t\", recall_score(y_test, y_predict_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArE1NPcTd5oI"
      },
      "source": [
        "# F1 Score Werte\n",
        "print(\"[F1] Trainingsdaten:\\t\", f1_score(y_train, y_predict_train))\n",
        "print(\"[F1] Testdaten:\\t\\t\", f1_score(y_test, y_predict_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N05E-tIkQ1mI"
      },
      "source": [
        "### Precision - Recall Tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htNEV45Of4p-"
      },
      "source": [
        "# Erinnerung:\n",
        "#############\n",
        "# Precision = TP / (TP + FP) --> Wieviele Ergebnisse sind \"sinnvoll\"\"? (d.h. der Anteil der TP zu den als POSITIVE ermittelten)\n",
        "# Recall = TP / (TP + FN)    --> Wieviele \"sinnvolle\" Ergebnisse wurden ermittelt? (d.h. der Anteil der TP zu den wirklich POSITIVEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOr47cNTfgj"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html\n",
        "\n",
        "# Berechne \"Score\" Werte -> Wie \"sicher\" ist sich der Klassifikator bei der Zuordnung der Testinstanzen?\n",
        "predict_scores_test = cross_val_predict(model, X_test, y_test, cv=5, method=\"decision_function\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG4HmJhDRwNG"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "\n",
        "# Berechne Precision und Recall Werte für jede einzelne Dateninstanz in den Testdaten (basierend auf Zielvariable und den berechneten Scores)\n",
        "precision_test, recall_test, thresholds_test = precision_recall_curve(y_test, predict_scores_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMQ_gqRXSH6z"
      },
      "source": [
        "# Zeichne Tradeoff\n",
        "plt.plot(thresholds_test, precision_test[0:-1], label = \"Precision\")\n",
        "plt.plot(thresholds_test, recall_test[0:-1], label = \"Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"Precision / Recall\")\n",
        "plt.title(\"Testdaten\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "#plt.ylim([0.88, 0.91]) # Details"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}